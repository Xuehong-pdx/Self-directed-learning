{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmenting Pandas With SQLite\n",
    "https://app.dataquest.io/m/166/augmenting-pandas-with-sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "conn = sqlite3.connect('Raw_data\\moma.db')\n",
    "moma_iter = pd.read_csv('Raw_data\\moma.csv', chunksize=1000)\n",
    "for chunk in moma_iter:\n",
    "    chunk.to_sql(\"exhibitions\", conn, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type\tDescription\n",
    "NULL\tThe value is a NULL value\n",
    "INTEGER\tThe value is a signed integer, stored in 1, 2, 3, 4, 6, or 8 bytes, depending on the magnitude of the value\n",
    "REAL\tThe value is a floating point value, stored as an 8-byte IEEE floating point number\n",
    "TEXT\tThe value is a text string, stored using the database encoding (UTF-8, UTF-16BE or UTF-16LE)\n",
    "BLOB\tThe value is a blob of data, stored exactly as it was entered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query moma.db and return the column types for the exhibitions table\n",
    "results_df = pd.read_sql('PRAGMA table_info(exhibitions);', conn)\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moma_iter = pd.read_csv('Raw_data\\moma.csv', chunksize=1000)\n",
    "for chunk in moma_iter:\n",
    "    chunk['ExhibitionSortOrder'] = chunk['ExhibitionSortOrder'].astype('int16')\n",
    "    chunk.to_sql(\"exhibitions\", conn, if_exists='append', index=False)\n",
    "results_df = pd.read_sql('PRAGMA table_info(exhibitions);', conn)\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the exhibitions table in moma.db to return both the unique values in the ExhibitionID column and the counts\n",
    "q = 'select exhibitionid, count(*) as counts from exhibitions group by exhibitionid order by counts desc;'\n",
    "eid_counts = pd.read_sql(q, conn)\n",
    "print(eid_counts.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the exhibitions table in moma.db, return the ExhibitionID column as a dataframe\n",
    "q = 'select exhibitionid from exhibitions;'\n",
    "eid_df = pd.read_sql(q, conn)\n",
    "eid_pandas_counts = eid_df['ExhibitionID'].value_counts()\n",
    "print(eid_pandas_counts.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read results in as dataframe chunks and then batch process the chunks\n",
    "import collections as coll\n",
    "q = 'select exhibitionid from exhibitions;'\n",
    "chunk_iter = pd.read_sql(q, conn, chunksize=100)\n",
    "dict = {} \n",
    "for chunk in chunk_iter:\n",
    "    c = chunk['ExhibitionID'].value_counts()\n",
    "    for inx, value in c.iteritems():\n",
    "        if inx in dict:\n",
    "            dict[inx] += value\n",
    "        else:\n",
    "            dict[inx] = value\n",
    "s = coll.Counter(dict)\n",
    "s.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guided Project: Analyzing Startup Fundraising Deals from Crunchbase\n",
    "https://app.dataquest.io/m/167/guided-project%3A-analyzing-startup-fundraising-deals-from-crunchbase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = 99\n",
    "chunk_iter = pd.read_csv('Raw_data\\crunchbase-investments.csv', chunksize=5000, encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.579195022583008\n",
      "5.528186798095703\n",
      "5.535004615783691\n",
      "5.528155326843262\n",
      "5.524299621582031\n",
      "5.553397178649902\n",
      "5.531391143798828\n",
      "5.509613037109375\n",
      "5.396082878112793\n",
      "4.63945198059082\n",
      "2.663668632507324\n",
      "total_mem: 56.98844623565674\n"
     ]
    }
   ],
   "source": [
    "total_mem = 0\n",
    "for chunk in chunk_iter:\n",
    "    mem = chunk.memory_usage(deep=True).sum()/(1024*1024)\n",
    "    print(mem)\n",
    "    total_mem += mem\n",
    "print('total_mem:', total_mem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company_category_code       643\n",
      "company_city                533\n",
      "company_country_code          1\n",
      "company_name                  1\n",
      "company_permalink             1\n",
      "company_region                1\n",
      "company_state_code          492\n",
      "funded_at                     3\n",
      "funded_month                  3\n",
      "funded_quarter                3\n",
      "funded_year                   3\n",
      "funding_round_type            3\n",
      "investor_category_code    50427\n",
      "investor_city             12480\n",
      "investor_country_code     12001\n",
      "investor_name                 2\n",
      "investor_permalink            2\n",
      "investor_region               2\n",
      "investor_state_code       16809\n",
      "raised_amount_usd          3599\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "chunk_iter = pd.read_csv('Raw_data\\crunchbase-investments.csv', chunksize=5000, encoding='ISO-8859-1')\n",
    "ls = []\n",
    "for chunk in chunk_iter:\n",
    "    c = chunk.isnull().sum()\n",
    "    ls.append(c)\n",
    "cc = pd.concat(ls)\n",
    "unique_cc = cc.groupby(cc.index).sum()\n",
    "unique_cc.sort_values()\n",
    "print(unique_cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> l=[1,2,3]\n",
      "... for i in l:\n",
      "...     i=i+2\n",
      "...\n",
      ">>> l=[1,2,3]\n",
      "... for i in l:\n",
      "...     i=i+2\n",
      "... l\n",
      "...\n",
      ">>> l=[1,2,3]\n",
      "... for i in l:\n",
      "...     print(i+2)\n",
      "...\n",
      ">>> original_prices = [1.25, -9.45, 10.22, 3.78, -5.92, 1.16]\n",
      "... prices = [i if i > 0 else 0 for i in original_prices]\n",
      "... prices\n",
      "...\n",
      ">>> %history -p\n"
     ]
    }
   ],
   "source": [
    "%history -p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying SQLite from Python\n",
    "https://app.dataquest.io/m/462/querying-sqlite-from-python/6/creating-a-cursor-and-running-a-query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('PETROLEUM ENGINEERING',), ('MINING AND MINERAL ENGINEERING',), ('METALLURGICAL ENGINEERING',), ('NAVAL ARCHITECTURE AND MARINE ENGINEERING',), ('CHEMICAL ENGINEERING',)]\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect(\"Raw_data\\jobs.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "query = \"select Major from recent_grads;\"\n",
    "cursor.execute(query)\n",
    "majors = cursor.fetchall()\n",
    "print(majors[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('PETROLEUM ENGINEERING',), ('MINING AND MINERAL ENGINEERING',), ('METALLURGICAL ENGINEERING',), ('NAVAL ARCHITECTURE AND MARINE ENGINEERING',), ('CHEMICAL ENGINEERING',)]\n"
     ]
    }
   ],
   "source": [
    "query = \"select Major from recent_grads;\"\n",
    "majors = conn.execute(query).fetchall()\n",
    "print(majors[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PETROLEUM ENGINEERING', 'Engineering'),\n",
       " ('MINING AND MINERAL ENGINEERING', 'Engineering'),\n",
       " ('METALLURGICAL ENGINEERING', 'Engineering'),\n",
       " ('NAVAL ARCHITECTURE AND MARINE ENGINEERING', 'Engineering'),\n",
       " ('CHEMICAL ENGINEERING', 'Engineering')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"select Major,Major_category from recent_grads;\"\n",
    "cursor.execute(query)\n",
    "cursor.fetchmany(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ZOOLOGY',),\n",
       " ('VISUAL AND PERFORMING ARTS',),\n",
       " ('UNITED STATES HISTORY',),\n",
       " ('TREATMENT THERAPY PROFESSIONS',),\n",
       " ('TRANSPORTATION SCIENCES AND TECHNOLOGIES',)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"select Major from recent_grads order by Major desc;\"\n",
    "reverse_alphabetical = conn.cursor().execute(query).fetchall()\n",
    "reverse_alphabetical[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT c.*, f.name country_name FROM facts f\n",
    "INNER JOIN cities c ON c.facts_id = f.id\n",
    "LIMIT 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT f.name country, c.name capital_city FROM cities c\n",
    "INNER JOIN facts f ON f.id = c.facts_id\n",
    "WHERE c.capital = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a join and a subquery, write a query that returns capital cities with populations of over 10 million ordered from largest to smallest\n",
    "SELECT c.name capital_city, f.name country, c.population population\n",
    "FROM facts f\n",
    "INNER JOIN (\n",
    "            SELECT * FROM cities\n",
    "            WHERE capital = 1\n",
    "            AND population > 10000000\n",
    "           ) c ON c.facts_id = f.id\n",
    "ORDER BY 3 DESC;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
